\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{a4wide}
\title{Reconstructed abstract of the paper ``Feature Selection via Quadratic Programming''}
\date{}
\begin{document}
\maketitle

\begin{abstract}
This paper presents a feature selection method to solve the multicollinearity problem in data fitting. The approach, based on quadratic programming, selects features by considering their relevance and similarity, leading to more stable and compact models. Comparative experiments with LARS, Lasso, Ridge, and other methods demonstrate the superiority of this approach on both synthetic and real data sets.
\end{abstract}
\paragraph{Keywords:} Feature selection, multicollinearity, quadratic programming, data fitting

\paragraph{Highlights:}
\begin{enumerate}
    \item New method to address multicollinearity in feature selection.
    \item Quadratic programming minimizes feature correlation.
    \item The method improves model stability and performance.
\end{enumerate}

\section{Introduction}
The multicollinearity problem affects the stability of regression models. Traditional methods like LARS, Lasso, and Ridge may fail in the presence of high feature correlation. This paper introduces a quadratic programming approach that optimizes the feature selection process, considering both feature relevance and inter-feature similarities, resulting in more robust models. Comparative analysis proves the effectiveness of the proposed method.

\bibliographystyle{unsrt}
\bibliography{feature-selection}
\end{document}
